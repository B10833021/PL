{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 邏輯回歸\n",
    "# https://medium.com/@yanweiliu/python%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98-%E5%9B%9B-%E4%BD%BF%E7%94%A8scikit-learn%E9%80%B2%E8%A1%8C%E9%82%8F%E8%BC%AF%E8%BF%B4%E6%AD%B8%E5%88%86%E6%9E%90-a5769715015d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Input_A1_001</th>\n",
       "      <th>Input_A1_002</th>\n",
       "      <th>Input_A1_003</th>\n",
       "      <th>Input_A1_004</th>\n",
       "      <th>Input_A1_005</th>\n",
       "      <th>Input_A1_006</th>\n",
       "      <th>Input_A1_007</th>\n",
       "      <th>Input_A1_008</th>\n",
       "      <th>Input_A1_009</th>\n",
       "      <th>...</th>\n",
       "      <th>Input_C_134</th>\n",
       "      <th>Input_C_135</th>\n",
       "      <th>Input_C_136</th>\n",
       "      <th>Input_C_137</th>\n",
       "      <th>Output_A1</th>\n",
       "      <th>Output_A2</th>\n",
       "      <th>Output_A3</th>\n",
       "      <th>Output_A4</th>\n",
       "      <th>Output_A5</th>\n",
       "      <th>Output_A6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Test1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.202</td>\n",
       "      <td>4.280</td>\n",
       "      <td>2.804</td>\n",
       "      <td>4.805</td>\n",
       "      <td>3.178</td>\n",
       "      <td>2.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Test2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.303</td>\n",
       "      <td>4.113</td>\n",
       "      <td>2.949</td>\n",
       "      <td>3.073</td>\n",
       "      <td>3.539</td>\n",
       "      <td>4.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Test3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.078</td>\n",
       "      <td>3.672</td>\n",
       "      <td>4.303</td>\n",
       "      <td>4.508</td>\n",
       "      <td>3.734</td>\n",
       "      <td>3.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Test4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.816</td>\n",
       "      <td>3.928</td>\n",
       "      <td>2.827</td>\n",
       "      <td>3.098</td>\n",
       "      <td>3.616</td>\n",
       "      <td>3.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Test5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.015</td>\n",
       "      <td>3.672</td>\n",
       "      <td>4.514</td>\n",
       "      <td>4.165</td>\n",
       "      <td>3.856</td>\n",
       "      <td>3.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>Test91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.201</td>\n",
       "      <td>3.300</td>\n",
       "      <td>4.069</td>\n",
       "      <td>3.265</td>\n",
       "      <td>3.602</td>\n",
       "      <td>3.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>Test92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.050</td>\n",
       "      <td>3.502</td>\n",
       "      <td>3.252</td>\n",
       "      <td>3.169</td>\n",
       "      <td>3.689</td>\n",
       "      <td>3.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>Test93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.561</td>\n",
       "      <td>3.739</td>\n",
       "      <td>3.243</td>\n",
       "      <td>3.779</td>\n",
       "      <td>3.113</td>\n",
       "      <td>3.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>Test94</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.863</td>\n",
       "      <td>3.962</td>\n",
       "      <td>3.145</td>\n",
       "      <td>3.212</td>\n",
       "      <td>3.156</td>\n",
       "      <td>3.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>Test95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.604</td>\n",
       "      <td>3.480</td>\n",
       "      <td>3.106</td>\n",
       "      <td>3.908</td>\n",
       "      <td>3.114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number  Input_A1_001  Input_A1_002  Input_A1_003  Input_A1_004  \\\n",
       "0    Test1          0.00          0.00          0.00          0.00   \n",
       "1    Test2          0.00          0.00          0.00          0.00   \n",
       "2    Test3          0.00          0.00          0.00          0.00   \n",
       "3    Test4          0.00          0.00          0.02          0.04   \n",
       "4    Test5          0.00          0.00          0.00          0.00   \n",
       "..     ...           ...           ...           ...           ...   \n",
       "90  Test91          0.00          0.00          0.00          0.00   \n",
       "91  Test92          0.00          0.00          0.02          0.04   \n",
       "92  Test93          0.00          0.00          0.00          0.00   \n",
       "93  Test94          0.08          0.06          0.03          0.00   \n",
       "94  Test95          0.00          0.00          0.00          0.00   \n",
       "\n",
       "    Input_A1_005  Input_A1_006  Input_A1_007  Input_A1_008  Input_A1_009  ...  \\\n",
       "0           0.00         0.002         0.004         0.002         0.004  ...   \n",
       "1           0.00         0.016         0.004         0.002         0.004  ...   \n",
       "2           0.00         0.006         0.006         0.002         0.002  ...   \n",
       "3           0.07         0.004         0.005         0.002         0.005  ...   \n",
       "4           0.00         0.012         0.008         0.002         0.003  ...   \n",
       "..           ...           ...           ...           ...           ...  ...   \n",
       "90          0.00         0.014         0.014         0.002         0.004  ...   \n",
       "91          0.09         0.010         0.004         0.002         0.004  ...   \n",
       "92          0.00         0.014         0.014         0.002         0.005  ...   \n",
       "93          0.00         0.006         0.010         0.002         0.004  ...   \n",
       "94          0.00         0.008         0.014         0.002         0.004  ...   \n",
       "\n",
       "    Input_C_134  Input_C_135  Input_C_136  Input_C_137  Output_A1  Output_A2  \\\n",
       "0        -0.004         4.00          1.0          1.0      3.202      4.280   \n",
       "1         0.003         4.00          1.0          1.0      4.303      4.113   \n",
       "2        -0.003         3.70          1.0          1.0      4.078      3.672   \n",
       "3         0.004         4.00          0.0          0.0      3.816      3.928   \n",
       "4         0.004         4.00          1.0          1.0      4.015      3.672   \n",
       "..          ...          ...          ...          ...        ...        ...   \n",
       "90        0.005         0.04          1.0          3.0      4.201      3.300   \n",
       "91        0.004         0.04          1.0          2.0      3.050      3.502   \n",
       "92        0.004         0.04          2.0          2.0      3.561      3.739   \n",
       "93       -0.005         0.04          2.0          2.0      2.863      3.962   \n",
       "94        0.006         0.04          2.0          2.0      3.021      3.604   \n",
       "\n",
       "    Output_A3  Output_A4  Output_A5  Output_A6  \n",
       "0       2.804      4.805      3.178      2.888  \n",
       "1       2.949      3.073      3.539      4.187  \n",
       "2       4.303      4.508      3.734      3.013  \n",
       "3       2.827      3.098      3.616      3.018  \n",
       "4       4.514      4.165      3.856      3.494  \n",
       "..        ...        ...        ...        ...  \n",
       "90      4.069      3.265      3.602      3.921  \n",
       "91      3.252      3.169      3.689      3.909  \n",
       "92      3.243      3.779      3.113      3.592  \n",
       "93      3.145      3.212      3.156      3.647  \n",
       "94      3.480      3.106      3.908      3.114  \n",
       "\n",
       "[95 rows x 268 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "# 導入數據 \n",
    "dataset = pd.read_csv(r'C:/Users/Cindy/Desktop/0728test.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,1:24]\n",
    "y = dataset['Output_A1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cindy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#載入邏輯迴歸\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#建立訓練組邏輯迴歸模型\n",
    "logmodel = LogisticRegression(solver='liblinear')\n",
    "logmodel.fit(X_train,y_train.astype('int'))\n",
    "#使用模型來預測\n",
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1-score \n",
    "## 精度和召回率的加權平均值\n",
    "## F1 = 2 * (precision * recall) / (precision + recall)\n",
    "## 在1時達到最佳值，在0時達到最差值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.69      1.00      0.82        20\n",
      "           4       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.69        29\n",
      "   macro avg       0.34      0.50      0.41        29\n",
      "weighted avg       0.48      0.69      0.56        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cindy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#載入classification_report來看預測和實際數值的差異，包含precision、recall、f1-score及support\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test.astype('int'),predictions.astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7575757575757576"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型分數\n",
    "from sklearn import metrics\n",
    "logmodel.score(X_train,y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_train).astype('int'))\n",
    "#print(\"Precision:\",metrics.precision_score(y_test, y_train).astype('int'))\n",
    "#print(\"Recall:\",metrics.recall_score(y_test, y_train).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  0],\n",
       "       [ 9,  0]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#建立confusion_matrix混淆矩陣\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test.astype('int'),predictions)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混淆矩陣說明\n",
    "## TN=True Negative\n",
    "## FP=False Positive\n",
    "## FN=False Negative\n",
    "## TP=True Positive\n",
    "## precison = TP / (TP + FP)\n",
    "## recall = TP / (TP + FN)\n",
    "## accuracy = (TP + TN) / (TN + FP + FN + TP)\n",
    "### F-beta score可視為precision和recall加權平均的值，數值介於0-1，最好是1。\n",
    "### support代表在測試組y實際值的發生次數。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 15.0, 'Predicted label')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
